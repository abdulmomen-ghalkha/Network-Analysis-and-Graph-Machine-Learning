{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dC5f5cIBm1_4"
   },
   "source": [
    "# Task\n",
    "Convert this data into a graph\n",
    "\n",
    "Here is all the data you need:\n",
    "\"citing.txt\"\n",
    "\"musae_git_edges.csv\"\n",
    "\"musae_git_features.json\"\n",
    "\"musae_git_target.csv\"\n",
    "\"README.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrVp-oDrm2ze"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "### Subtask:\n",
    "Load the provided CSV and JSON files into pandas DataFrames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoYPbTTtm3iT"
   },
   "source": [
    "**Reasoning**:\n",
    "Load the provided CSV and JSON files into pandas DataFrames and print the first few rows of each to verify.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "JmWfz5lAm336",
    "outputId": "387c0ff2-7272-4bda-ff9f-0b92985d9c9c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load musae_git_edges.csv\n",
    "try:\n",
    "    df_edges = pd.read_csv('musae_git_edges.csv')\n",
    "    display(df_edges.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: musae_git_edges.csv not found.\")\n",
    "    df_edges = None\n",
    "\n",
    "# Load musae_git_features.json\n",
    "try:\n",
    "    with open('musae_git_features.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    df_features = pd.DataFrame.from_dict(data, orient='index')\n",
    "    display(df_features.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: musae_git_features.json not found.\")\n",
    "    df_features = None\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Invalid JSON format in musae_git_features.json\")\n",
    "    df_features = None\n",
    "\n",
    "# Load musae_git_target.csv\n",
    "try:\n",
    "    df_target = pd.read_csv('musae_git_target.csv')\n",
    "    display(df_target.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: musae_git_target.csv not found.\")\n",
    "    df_target = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrP5WFTQm7p6"
   },
   "source": [
    "## Data exploration\n",
    "\n",
    "### Subtask:\n",
    "Explore the loaded dataframes (`df_edges`, `df_features`, and `df_target`) to understand their structure, identify key columns, and determine the relationships between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKLy294nm8dG"
   },
   "source": [
    "**Reasoning**:\n",
    "Inspect the dataframes to understand their structure, identify key columns, and determine relationships between them.  This includes examining shapes, data types, descriptive statistics, and unique values in potential identifier columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4jNmPYH_m8wX",
    "outputId": "bc121227-e28c-484b-f3ef-2bf65062e587"
   },
   "outputs": [],
   "source": [
    "# Inspect the shape and data types of each DataFrame\n",
    "print(\"df_edges shape:\", df_edges.shape)\n",
    "print(\"df_edges info:\")\n",
    "display(df_edges.info())\n",
    "\n",
    "print(\"\\ndf_features shape:\", df_features.shape)\n",
    "print(\"df_features info:\")\n",
    "display(df_features.info())\n",
    "\n",
    "print(\"\\ndf_target shape:\", df_target.shape)\n",
    "print(\"df_target info:\")\n",
    "display(df_target.info())\n",
    "\n",
    "\n",
    "# Identify node and edge columns\n",
    "print(\"\\ndf_edges unique values in id_1:\", df_edges['id_1'].nunique())\n",
    "print(\"df_edges unique values in id_2:\", df_edges['id_2'].nunique())\n",
    "\n",
    "print(\"\\ndf_features index (potential node IDs):\", df_features.index.nunique())\n",
    "print(\"First 5 values of the df_features index:\", df_features.index.unique()[:5])\n",
    "\n",
    "print(\"\\ndf_target unique values in id:\", df_target['id'].nunique())\n",
    "print(\"First 5 values of the id column in df_target:\", df_target['id'].unique()[:5])\n",
    "\n",
    "# Relationship analysis: check for missing values and inconsistencies\n",
    "print(\"\\nMissing values in df_edges:\", df_edges.isnull().sum().sum())\n",
    "print(\"Missing values in df_features:\", df_features.isnull().sum().sum())\n",
    "print(\"Missing values in df_target:\", df_target.isnull().sum().sum())\n",
    "\n",
    "# Visual inspection\n",
    "print(\"\\nFirst 5 rows of df_edges:\")\n",
    "display(df_edges.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of df_features:\")\n",
    "display(df_features.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows of df_target:\")\n",
    "display(df_target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYo8yElrnB_v"
   },
   "source": [
    "## Data wrangling\n",
    "\n",
    "### Subtask:\n",
    "Merge the three dataframes: `df_edges`, `df_features`, and `df_target` into a single dataframe suitable for graph creation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBk9V8-XnCxT"
   },
   "source": [
    "**Reasoning**:\n",
    "Convert the index of `df_features` to numeric and merge the three dataframes. Handle potential errors during index conversion and missing values after merging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uZiu23BTnDGt",
    "outputId": "ddef82aa-7861-493c-f485-21d883e11e92"
   },
   "outputs": [],
   "source": [
    "# Convert the index of df_features to numeric\n",
    "try:\n",
    "    df_features.index = pd.to_numeric(df_features.index, errors='raise')\n",
    "    df_features.index = df_features.index.astype('int64')\n",
    "except ValueError as e:\n",
    "    print(f\"Error converting index to numeric: {e}\")\n",
    "    # Handle the error, e.g., by removing or imputing problematic rows\n",
    "    # For this example, I will skip the problematic rows.\n",
    "    # In a real-world scenario, investigate the problematic rows and choose the appropriate method.\n",
    "    # problematic_indices = df_features.index[pd.to_numeric(df_features.index, errors='coerce').isnull()]\n",
    "    # df_features = df_features.drop(problematic_indices)\n",
    "    # df_features.index = pd.to_numeric(df_features.index, errors='coerce').dropna().astype('int64')\n",
    "\n",
    "# Merge df_features and df_target\n",
    "df_merged = pd.merge(df_features, df_target, left_index=True, right_on='id', how='inner')\n",
    "\n",
    "# Merge with df_edges\n",
    "df_final = pd.merge(df_merged, df_edges, left_on='id', right_on='id_1', how='inner')\n",
    "\n",
    "# Handle missing values\n",
    "# Check for missing values after merging\n",
    "print(\"Missing values in the final dataframe:\\n\", df_final.isnull().sum())\n",
    "# Since the missing values are mostly in the feature columns, we can impute them with the mean.\n",
    "for col in df_final.columns:\n",
    "    if df_final[col].isnull().any():\n",
    "        if pd.api.types.is_numeric_dtype(df_final[col]):\n",
    "            df_final[col] = df_final[col].fillna(df_final[col].mean())\n",
    "        else:\n",
    "            #Handle other data types if needed\n",
    "            pass\n",
    "\n",
    "print(df_final.shape)\n",
    "display(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NDp9k72nHGW"
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "### Subtask:\n",
    "Prepare the merged dataframe `df_final` for graph creation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjsVpovnnIWm"
   },
   "source": [
    "**Reasoning**:\n",
    "Identify node and edge columns, validate data types, and handle any remaining missing values in `df_final`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8atVzr3nnIt3",
    "outputId": "de5de2ca-ad8a-4b80-9d39-82004a4b2592"
   },
   "outputs": [],
   "source": [
    "# Identify node and edge columns\n",
    "source_nodes = df_final['id_1']\n",
    "target_nodes = df_final['id_2']\n",
    "\n",
    "# Validate data types\n",
    "# Check if node identifiers are already numeric\n",
    "if not pd.api.types.is_numeric_dtype(source_nodes):\n",
    "    try:\n",
    "        source_nodes = pd.to_numeric(source_nodes, errors='raise')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting source nodes to numeric: {e}\")\n",
    "        # Handle the error appropriately, e.g., by removing or imputing problematic values\n",
    "        # For demonstration, I'm skipping the problematic rows.\n",
    "        # In real-world scenarios, decide based on data understanding\n",
    "        pass\n",
    "\n",
    "if not pd.api.types.is_numeric_dtype(target_nodes):\n",
    "    try:\n",
    "        target_nodes = pd.to_numeric(target_nodes, errors='raise')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting target nodes to numeric: {e}\")\n",
    "        # Handle the error appropriately\n",
    "        pass\n",
    "\n",
    "# Update df_final with the corrected data types (if necessary)\n",
    "df_final['id_1'] = source_nodes\n",
    "df_final['id_2'] = target_nodes\n",
    "\n",
    "\n",
    "# Handle any remaining missing values (already handled in previous step)\n",
    "# Check if there are any remaining missing values\n",
    "print(\"Missing values in the final dataframe:\\n\", df_final.isnull().sum())\n",
    "\n",
    "# No further action needed as missing values are already imputed.\n",
    "\n",
    "\n",
    "# Feature scaling\n",
    "# Optional: Scale numerical features if needed for visualization or analysis.\n",
    "# Select numerical columns to scale\n",
    "numerical_cols = df_final.select_dtypes(include=['number']).columns\n",
    "# Exclude node ID columns\n",
    "numerical_cols = numerical_cols.drop(['id_1', 'id_2', 'id', 'ml_target'])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "df_final[numerical_cols] = scaler.fit_transform(df_final[numerical_cols])\n",
    "\n",
    "display(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byJDZlC1nNm1"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### Q&A\n",
    "No questions were posed in the provided task.\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "* Three CSV and JSON files (`musae_git_edges.csv`, `musae_git_features.json`, and `musae_git_target.csv`) were loaded into pandas DataFrames.\n",
    "* `df_features` contained a substantial number of missing values (increasing with higher column indices) that were later imputed with the mean for numerical features.\n",
    "* The index of `df_features` was of type 'object' while the corresponding 'id' columns in other dataframes were 'int64'. This required a type conversion to 'int64' to enable merging.\n",
    "* The number of unique values in `id_1` and `id_2` of `df_edges` (30,855 and 30,195 respectively) was lower than the number of unique nodes in `df_features` and `df_target` (37,700), indicating some nodes might not have any connections.\n",
    "* Numerical features in `df_final` were scaled using `MinMaxScaler` to a range of 0 to 1, excluding node IDs, `id`, and the target variable `ml_target`.\n",
    "* The final merged dataframe, `df_final`, has a shape of (289003, 47) and includes node features, target labels, and edge information.\n",
    "\n",
    "### Insights or Next Steps\n",
    "* Investigate the meaning of the features in `df_features` to potentially improve imputation strategies beyond mean imputation.\n",
    "* Explore the nodes without connections identified in `df_edges` to understand their significance in the context of the dataset.\n",
    "* Visualize the constructed graph to identify patterns and relationships between nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTZ9UOiuoJSr",
    "outputId": "95ef16e3-f357-4ee3-ec8a-f3bbef11f619"
   },
   "outputs": [],
   "source": [
    "# Step 2: Install Necessary Libraries\n",
    "# You can install networkx in Colab using pip\n",
    "#!pip install networkx==3.2.1\n",
    "\n",
    "# Step 3: Define Node Features and Labels\n",
    "# Identify the node ID column, edge columns, feature columns, and the target label column\n",
    "node_id_col = 'id'\n",
    "source_node_col = 'id_1'\n",
    "target_node_col = 'id_2'\n",
    "target_label_col = 'ml_target' # Based on the notebook's description of the target\n",
    "\n",
    "# Identify feature columns. Exclude IDs and the target label.\n",
    "feature_cols = [col for col in df_final.columns if col not in [node_id_col, source_node_col, target_node_col, target_label_col]]\n",
    "\n",
    "\n",
    "# Step 4: Create the Graph using NetworkX\n",
    "import networkx as nx\n",
    "\n",
    "# Create an empty graph. Use nx.Graph() for undirected based on \"mutual follower relationships\".\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with features and labels\n",
    "# We'll iterate through the unique node IDs present in the edge list and target data\n",
    "unique_nodes = pd.concat([df_final[source_node_col], df_final[target_node_col], df_final[node_id_col]]).unique()\n",
    "\n",
    "for node_id in unique_nodes:\n",
    "    # Find the rows in df_final corresponding to this node as either source, target, or id\n",
    "    node_data = df_final[(df_final[source_node_col] == node_id) | (df_final[target_node_col] == node_id) | (df_final[node_id_col] == node_id)].iloc[0] # Take the first matching row\n",
    "\n",
    "    # Extract features for this node\n",
    "    features = node_data[feature_cols].to_dict()\n",
    "\n",
    "    # Extract the target label\n",
    "    label = node_data[target_label_col]\n",
    "\n",
    "    # Add the node to the graph with features and label\n",
    "    G.add_node(node_id, label=label, features=features)\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# Iterate through the edges in df_final\n",
    "for index, row in df_final.iterrows():\n",
    "    source_node = row[source_node_col]\n",
    "    target_node = row[target_node_col]\n",
    "    G.add_edge(source_node, target_node)\n",
    "\n",
    "print(f\"Graph created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5KNpsOFoKeZ",
    "outputId": "7cea8587-9c4c-48a4-a082-85489476dcb6"
   },
   "outputs": [],
   "source": [
    "# prompt: print node with their features\n",
    "\n",
    "# Print node data (features and label) for a few nodes\n",
    "print(\"\\nNode data for a few nodes:\")\n",
    "for i, node_id in enumerate(list(G.nodes)[:5]): # Print data for the first 5 nodes\n",
    "    node_data = G.nodes[node_id]\n",
    "    print(f\"\\nNode ID: {node_id}\")\n",
    "    print(f\"  Label: {node_data.get('label')}\")\n",
    "    print(f\"  Features: {node_data.get('features')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fc8f8uXqopby",
    "outputId": "cc30fd63-c567-4031-8f8b-ad3ec743ecbe"
   },
   "outputs": [],
   "source": [
    "# prompt: print node labels\n",
    "\n",
    "# Print the labels of the nodes\n",
    "print(\"\\nNode labels:\")\n",
    "for node, data in G.nodes(data=True):\n",
    "  print(f\"Node {node}: Label = {data.get('label')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnLI_S9hoxFr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
